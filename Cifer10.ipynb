{"nbformat":4,"nbformat_minor":5,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.8"},"colab":{"name":"Untitled.ipynb","provenance":[]},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"7c5a796d","executionInfo":{"status":"ok","timestamp":1626364503736,"user_tz":-330,"elapsed":1615,"user":{"displayName":"ROHIT KUMAR","photoUrl":"","userId":"05114210246644333889"}}},"source":["import tensorflow as tf\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import pandas as pd\n","import seaborn as sns"],"id":"7c5a796d","execution_count":1,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IIbukQuP0Dkz","executionInfo":{"status":"ok","timestamp":1626364525464,"user_tz":-330,"elapsed":21730,"user":{"displayName":"ROHIT KUMAR","photoUrl":"","userId":"05114210246644333889"}},"outputId":"f58eb522-ced2-47cb-db40-71ddc4620ebb"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"id":"IIbukQuP0Dkz","execution_count":2,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"6jbW1w8M0Icy","executionInfo":{"status":"ok","timestamp":1626364526119,"user_tz":-330,"elapsed":658,"user":{"displayName":"ROHIT KUMAR","photoUrl":"","userId":"05114210246644333889"}}},"source":["import os\n","ROOT = \"/content/drive/MyDrive/Collab notebook/Assignment/Cifer10\"\n","os.chdir(ROOT)\n","assert ROOT == os.getcwd()"],"id":"6jbW1w8M0Icy","execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"d0503e24","executionInfo":{"status":"ok","timestamp":1626364533356,"user_tz":-330,"elapsed":7240,"user":{"displayName":"ROHIT KUMAR","photoUrl":"","userId":"05114210246644333889"}},"outputId":"9777c9c2-f62c-446d-c88e-531047bdb9d7"},"source":["cifar10 = tf.keras.datasets.cifar10\n","\n","(X_train, y_train),(X_test, y_test) = cifar10.load_data()\n","\n","print(\"The MNIST dataset has a training size of %d examples\" %len(X_train))\n","print(\"The MNIST dataset has a test size of %d examples\" %len(X_test))"],"id":"d0503e24","execution_count":4,"outputs":[{"output_type":"stream","text":["Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n","170500096/170498071 [==============================] - 5s 0us/step\n","The MNIST dataset has a training size of 50000 examples\n","The MNIST dataset has a test size of 10000 examples\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":283},"id":"htucVEqV0i6J","executionInfo":{"status":"ok","timestamp":1626364533357,"user_tz":-330,"elapsed":11,"user":{"displayName":"ROHIT KUMAR","photoUrl":"","userId":"05114210246644333889"}},"outputId":"4c42e580-4ecf-4b33-c572-509f9a842aaa"},"source":["plt.imshow(X_train[4])"],"id":"htucVEqV0i6J","execution_count":5,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<matplotlib.image.AxesImage at 0x7fdd8db07d10>"]},"metadata":{"tags":[]},"execution_count":5},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zK_RP8EX1LEU","executionInfo":{"status":"ok","timestamp":1626364533357,"user_tz":-330,"elapsed":8,"user":{"displayName":"ROHIT KUMAR","photoUrl":"","userId":"05114210246644333889"}},"outputId":"64af85c3-0f9e-43f9-f581-02ff1d6bfede"},"source":["y_train"],"id":"zK_RP8EX1LEU","execution_count":6,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[6],\n","       [9],\n","       [9],\n","       ...,\n","       [9],\n","       [1],\n","       [1]], dtype=uint8)"]},"metadata":{"tags":[]},"execution_count":6}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"f61f37bc","executionInfo":{"status":"ok","timestamp":1626364534015,"user_tz":-330,"elapsed":664,"user":{"displayName":"ROHIT KUMAR","photoUrl":"","userId":"05114210246644333889"}},"outputId":"ac10643b-04e9-4cab-bc74-b9184492d360"},"source":["X_train = X_train.astype('float32')/255\n","X_test = X_test.astype('float32')/255\n","\n","print('X_train shaoe:', X_train.shape)\n","print(X_train.shape[0], 'train samples')\n","print(X_test.shape[0], 'test samples')"],"id":"f61f37bc","execution_count":7,"outputs":[{"output_type":"stream","text":["X_train shaoe: (50000, 32, 32, 3)\n","50000 train samples\n","10000 test samples\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"12d4db90","executionInfo":{"status":"ok","timestamp":1626364534015,"user_tz":-330,"elapsed":6,"user":{"displayName":"ROHIT KUMAR","photoUrl":"","userId":"05114210246644333889"}},"outputId":"286e62a0-facf-4d42-c014-49916dac8976"},"source":["y_train"],"id":"12d4db90","execution_count":8,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[6],\n","       [9],\n","       [9],\n","       ...,\n","       [9],\n","       [1],\n","       [1]], dtype=uint8)"]},"metadata":{"tags":[]},"execution_count":8}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"c0b5d3e1","executionInfo":{"status":"ok","timestamp":1626364534016,"user_tz":-330,"elapsed":6,"user":{"displayName":"ROHIT KUMAR","photoUrl":"","userId":"05114210246644333889"}},"outputId":"72f0de4d-035c-47ab-a578-ffbdbf34fb62"},"source":["from keras.utils import np_utils\n","\n","num_classes = 10 \n","# print first ten (integer-valued) training labels\n","print('Integer-valued labels:')\n","print(y_train[:10])\n","\n","# one-hot encode the labels\n","# convert class vectors to binary class matrices\n","y_train = np_utils.to_categorical(y_train, num_classes)\n","y_test = np_utils.to_categorical(y_test, num_classes)\n","\n","# print first ten (one-hot) training labels\n","print('One-hot labels:')\n","print(y_train[:10])"],"id":"c0b5d3e1","execution_count":9,"outputs":[{"output_type":"stream","text":["Integer-valued labels:\n","[[6]\n"," [9]\n"," [9]\n"," [4]\n"," [1]\n"," [1]\n"," [2]\n"," [7]\n"," [8]\n"," [3]]\n","One-hot labels:\n","[[0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n"," [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n"," [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n"," [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n"," [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n"," [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n"," [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n"," [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n"," [0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n"," [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ed110aa4","executionInfo":{"status":"ok","timestamp":1626364534016,"user_tz":-330,"elapsed":5,"user":{"displayName":"ROHIT KUMAR","photoUrl":"","userId":"05114210246644333889"}},"outputId":"fb05ea10-fa70-430a-8f08-5f475ba5b112"},"source":["X_train.shape"],"id":"ed110aa4","execution_count":10,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(50000, 32, 32, 3)"]},"metadata":{"tags":[]},"execution_count":10}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6bd57b64","executionInfo":{"status":"ok","timestamp":1626364534016,"user_tz":-330,"elapsed":4,"user":{"displayName":"ROHIT KUMAR","photoUrl":"","userId":"05114210246644333889"}},"outputId":"7e29fe5c-3e7a-4b7f-9df5-1e73f70ec26e"},"source":["img_rows, img_cols = 32, 32\n","\n","X_train = X_train.reshape(X_train.shape[0], img_rows, img_cols, 3)\n","X_test = X_test.reshape(X_test.shape[0], img_rows, img_cols, 3)\n","input_shape = (img_rows, img_cols, 3)\n","\n","print('input_shape: ', input_shape)\n","print('x_train shape:', X_train.shape)"],"id":"6bd57b64","execution_count":11,"outputs":[{"output_type":"stream","text":["input_shape:  (32, 32, 3)\n","x_train shape: (50000, 32, 32, 3)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"30d89123","executionInfo":{"status":"ok","timestamp":1626364539968,"user_tz":-330,"elapsed":5955,"user":{"displayName":"ROHIT KUMAR","photoUrl":"","userId":"05114210246644333889"}},"outputId":"da05b2e0-15a6-429f-e623-7e5ba70a197b"},"source":["## Model 1\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, GlobalAveragePooling2D\n","\n","# build the model object\n","model = Sequential()\n","\n","# CONV_1: add CONV layer with RELU activation and depth = 32 kernels\n","model.add(Conv2D(32, kernel_size=(3, 3), padding='same',activation='relu',input_shape=(32,32,3)))\n","model.add(Conv2D(64, kernel_size=(3, 3), padding='same',activation='relu',input_shape=(32,32,3)))\n","model.add(Conv2D(128, kernel_size=(3, 3), padding='same',activation='relu',input_shape=(32,32,3)))\n","# POOL_1: downsample the image to choose the best features \n","model.add(MaxPooling2D(pool_size=(2, 2)))\n","\n","# CONV_2: here we increase the depth to 64\n","model.add(Conv2D(64, (3, 3),padding='same', activation='relu'))\n","model.add(Conv2D(128, (3, 3),padding='same', activation='relu'))\n","# POOL_2: more downsampling\n","model.add(MaxPooling2D(pool_size=(2, 2)))\n","\n","# flatten since too many dimensions, we only want a classification output\n","model.add(Flatten())\n","\n","# FC_1: fully connected to get all relevant data\n","model.add(Dense(64, activation='relu'))\n","\n","# FC_2: output a softmax to squash the matrix into output probabilities for the 10 classes\n","model.add(Dense(10, activation='softmax'))\n","\n","model.summary()"],"id":"30d89123","execution_count":12,"outputs":[{"output_type":"stream","text":["Model: \"sequential\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","conv2d (Conv2D)              (None, 32, 32, 32)        896       \n","_________________________________________________________________\n","conv2d_1 (Conv2D)            (None, 32, 32, 64)        18496     \n","_________________________________________________________________\n","conv2d_2 (Conv2D)            (None, 32, 32, 128)       73856     \n","_________________________________________________________________\n","max_pooling2d (MaxPooling2D) (None, 16, 16, 128)       0         \n","_________________________________________________________________\n","conv2d_3 (Conv2D)            (None, 16, 16, 64)        73792     \n","_________________________________________________________________\n","conv2d_4 (Conv2D)            (None, 16, 16, 128)       73856     \n","_________________________________________________________________\n","max_pooling2d_1 (MaxPooling2 (None, 8, 8, 128)         0         \n","_________________________________________________________________\n","flatten (Flatten)            (None, 8192)              0         \n","_________________________________________________________________\n","dense (Dense)                (None, 64)                524352    \n","_________________________________________________________________\n","dense_1 (Dense)              (None, 10)                650       \n","=================================================================\n","Total params: 765,898\n","Trainable params: 765,898\n","Non-trainable params: 0\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"e3ee457e","executionInfo":{"status":"ok","timestamp":1626365310236,"user_tz":-330,"elapsed":770270,"user":{"displayName":"ROHIT KUMAR","photoUrl":"","userId":"05114210246644333889"}},"outputId":"cb4ed62b-c51b-4911-d5b1-8abfc0000456"},"source":["# compile the model\n","model.compile(loss='categorical_crossentropy', optimizer='rmsprop', \n","              metrics=['accuracy'])\n","from tensorflow.keras.callbacks import ModelCheckpoint   \n","\n","# train the model\n","checkpointer = ModelCheckpoint(filepath='model.weights.best.hdf5', verbose=1, \n","                               save_best_only=True)\n","hist = model.fit(X_train, y_train, batch_size=32, epochs=50,\n","          validation_data=(X_test, y_test), callbacks=[checkpointer], \n","          verbose=1, shuffle=True)"],"id":"e3ee457e","execution_count":13,"outputs":[{"output_type":"stream","text":["Epoch 1/50\n","1563/1563 [==============================] - 47s 10ms/step - loss: 1.4636 - accuracy: 0.4737 - val_loss: 1.0334 - val_accuracy: 0.6383\n","\n","Epoch 00001: val_loss improved from inf to 1.03340, saving model to model.weights.best.hdf5\n","Epoch 2/50\n","1563/1563 [==============================] - 15s 9ms/step - loss: 0.9058 - accuracy: 0.6840 - val_loss: 0.7978 - val_accuracy: 0.7240\n","\n","Epoch 00002: val_loss improved from 1.03340 to 0.79775, saving model to model.weights.best.hdf5\n","Epoch 3/50\n","1563/1563 [==============================] - 15s 10ms/step - loss: 0.6993 - accuracy: 0.7604 - val_loss: 0.7540 - val_accuracy: 0.7405\n","\n","Epoch 00003: val_loss improved from 0.79775 to 0.75401, saving model to model.weights.best.hdf5\n","Epoch 4/50\n","1563/1563 [==============================] - 15s 9ms/step - loss: 0.5761 - accuracy: 0.8036 - val_loss: 0.8087 - val_accuracy: 0.7466\n","\n","Epoch 00004: val_loss did not improve from 0.75401\n","Epoch 5/50\n","1563/1563 [==============================] - 15s 9ms/step - loss: 0.4925 - accuracy: 0.8345 - val_loss: 0.7368 - val_accuracy: 0.7651\n","\n","Epoch 00005: val_loss improved from 0.75401 to 0.73681, saving model to model.weights.best.hdf5\n","Epoch 6/50\n","1563/1563 [==============================] - 15s 9ms/step - loss: 0.4377 - accuracy: 0.8530 - val_loss: 0.7582 - val_accuracy: 0.7571\n","\n","Epoch 00006: val_loss did not improve from 0.73681\n","Epoch 7/50\n","1563/1563 [==============================] - 15s 9ms/step - loss: 0.3955 - accuracy: 0.8677 - val_loss: 0.9736 - val_accuracy: 0.7349\n","\n","Epoch 00007: val_loss did not improve from 0.73681\n","Epoch 8/50\n","1563/1563 [==============================] - 15s 9ms/step - loss: 0.3747 - accuracy: 0.8786 - val_loss: 0.8430 - val_accuracy: 0.7321\n","\n","Epoch 00008: val_loss did not improve from 0.73681\n","Epoch 9/50\n","1563/1563 [==============================] - 14s 9ms/step - loss: 0.3652 - accuracy: 0.8829 - val_loss: 1.0379 - val_accuracy: 0.7391\n","\n","Epoch 00009: val_loss did not improve from 0.73681\n","Epoch 10/50\n","1563/1563 [==============================] - 14s 9ms/step - loss: 0.3659 - accuracy: 0.8851 - val_loss: 1.2642 - val_accuracy: 0.7510\n","\n","Epoch 00010: val_loss did not improve from 0.73681\n","Epoch 11/50\n","1563/1563 [==============================] - 15s 9ms/step - loss: 0.3619 - accuracy: 0.8857 - val_loss: 1.2225 - val_accuracy: 0.7444\n","\n","Epoch 00011: val_loss did not improve from 0.73681\n","Epoch 12/50\n","1563/1563 [==============================] - 15s 9ms/step - loss: 0.3595 - accuracy: 0.8911 - val_loss: 1.2030 - val_accuracy: 0.7670\n","\n","Epoch 00012: val_loss did not improve from 0.73681\n","Epoch 13/50\n","1563/1563 [==============================] - 14s 9ms/step - loss: 0.3533 - accuracy: 0.8939 - val_loss: 1.1163 - val_accuracy: 0.7581\n","\n","Epoch 00013: val_loss did not improve from 0.73681\n","Epoch 14/50\n","1563/1563 [==============================] - 15s 9ms/step - loss: 0.3628 - accuracy: 0.8922 - val_loss: 1.5835 - val_accuracy: 0.7413\n","\n","Epoch 00014: val_loss did not improve from 0.73681\n","Epoch 15/50\n","1563/1563 [==============================] - 14s 9ms/step - loss: 0.3601 - accuracy: 0.8927 - val_loss: 0.9398 - val_accuracy: 0.7277\n","\n","Epoch 00015: val_loss did not improve from 0.73681\n","Epoch 16/50\n","1563/1563 [==============================] - 15s 9ms/step - loss: 0.3723 - accuracy: 0.8919 - val_loss: 1.2637 - val_accuracy: 0.7451\n","\n","Epoch 00016: val_loss did not improve from 0.73681\n","Epoch 17/50\n","1563/1563 [==============================] - 15s 9ms/step - loss: 0.3797 - accuracy: 0.8918 - val_loss: 1.3880 - val_accuracy: 0.7165\n","\n","Epoch 00017: val_loss did not improve from 0.73681\n","Epoch 18/50\n","1563/1563 [==============================] - 14s 9ms/step - loss: 0.3721 - accuracy: 0.8947 - val_loss: 1.2389 - val_accuracy: 0.7380\n","\n","Epoch 00018: val_loss did not improve from 0.73681\n","Epoch 19/50\n","1563/1563 [==============================] - 14s 9ms/step - loss: 0.3673 - accuracy: 0.8951 - val_loss: 1.2627 - val_accuracy: 0.7209\n","\n","Epoch 00019: val_loss did not improve from 0.73681\n","Epoch 20/50\n","1563/1563 [==============================] - 15s 9ms/step - loss: 0.3752 - accuracy: 0.8942 - val_loss: 1.5694 - val_accuracy: 0.7695\n","\n","Epoch 00020: val_loss did not improve from 0.73681\n","Epoch 21/50\n","1563/1563 [==============================] - 15s 10ms/step - loss: 0.3705 - accuracy: 0.8957 - val_loss: 1.5885 - val_accuracy: 0.7409\n","\n","Epoch 00021: val_loss did not improve from 0.73681\n","Epoch 22/50\n","1563/1563 [==============================] - 15s 9ms/step - loss: 0.3625 - accuracy: 0.8984 - val_loss: 1.0294 - val_accuracy: 0.7243\n","\n","Epoch 00022: val_loss did not improve from 0.73681\n","Epoch 23/50\n","1563/1563 [==============================] - 15s 10ms/step - loss: 0.3692 - accuracy: 0.8943 - val_loss: 1.2395 - val_accuracy: 0.7162\n","\n","Epoch 00023: val_loss did not improve from 0.73681\n","Epoch 24/50\n","1563/1563 [==============================] - 15s 9ms/step - loss: 0.3831 - accuracy: 0.8973 - val_loss: 1.6911 - val_accuracy: 0.7385\n","\n","Epoch 00024: val_loss did not improve from 0.73681\n","Epoch 25/50\n","1563/1563 [==============================] - 14s 9ms/step - loss: 0.3701 - accuracy: 0.8962 - val_loss: 2.0396 - val_accuracy: 0.7501\n","\n","Epoch 00025: val_loss did not improve from 0.73681\n","Epoch 26/50\n","1563/1563 [==============================] - 14s 9ms/step - loss: 0.3716 - accuracy: 0.8971 - val_loss: 2.4928 - val_accuracy: 0.7247\n","\n","Epoch 00026: val_loss did not improve from 0.73681\n","Epoch 27/50\n","1563/1563 [==============================] - 15s 9ms/step - loss: 0.3660 - accuracy: 0.8984 - val_loss: 1.5561 - val_accuracy: 0.7480\n","\n","Epoch 00027: val_loss did not improve from 0.73681\n","Epoch 28/50\n","1563/1563 [==============================] - 15s 10ms/step - loss: 0.3559 - accuracy: 0.9024 - val_loss: 2.0235 - val_accuracy: 0.7341\n","\n","Epoch 00028: val_loss did not improve from 0.73681\n","Epoch 29/50\n","1563/1563 [==============================] - 15s 10ms/step - loss: 0.3709 - accuracy: 0.9000 - val_loss: 2.1113 - val_accuracy: 0.7436\n","\n","Epoch 00029: val_loss did not improve from 0.73681\n","Epoch 30/50\n","1563/1563 [==============================] - 15s 9ms/step - loss: 0.3695 - accuracy: 0.9010 - val_loss: 1.8182 - val_accuracy: 0.7077\n","\n","Epoch 00030: val_loss did not improve from 0.73681\n","Epoch 31/50\n","1563/1563 [==============================] - 15s 9ms/step - loss: 0.3845 - accuracy: 0.9005 - val_loss: 3.3841 - val_accuracy: 0.7104\n","\n","Epoch 00031: val_loss did not improve from 0.73681\n","Epoch 32/50\n","1563/1563 [==============================] - 15s 9ms/step - loss: 0.3767 - accuracy: 0.8977 - val_loss: 1.4523 - val_accuracy: 0.6935\n","\n","Epoch 00032: val_loss did not improve from 0.73681\n","Epoch 33/50\n","1563/1563 [==============================] - 15s 9ms/step - loss: 0.3665 - accuracy: 0.9045 - val_loss: 2.1623 - val_accuracy: 0.7523\n","\n","Epoch 00033: val_loss did not improve from 0.73681\n","Epoch 34/50\n","1563/1563 [==============================] - 14s 9ms/step - loss: 0.3525 - accuracy: 0.9028 - val_loss: 1.6057 - val_accuracy: 0.7455\n","\n","Epoch 00034: val_loss did not improve from 0.73681\n","Epoch 35/50\n","1563/1563 [==============================] - 14s 9ms/step - loss: 0.3454 - accuracy: 0.9072 - val_loss: 2.4523 - val_accuracy: 0.7299\n","\n","Epoch 00035: val_loss did not improve from 0.73681\n","Epoch 36/50\n","1563/1563 [==============================] - 15s 10ms/step - loss: 0.3565 - accuracy: 0.9079 - val_loss: 1.2684 - val_accuracy: 0.6460\n","\n","Epoch 00036: val_loss did not improve from 0.73681\n","Epoch 37/50\n","1563/1563 [==============================] - 15s 10ms/step - loss: 0.3379 - accuracy: 0.9049 - val_loss: 1.5717 - val_accuracy: 0.7539\n","\n","Epoch 00037: val_loss did not improve from 0.73681\n","Epoch 38/50\n","1563/1563 [==============================] - 14s 9ms/step - loss: 0.3429 - accuracy: 0.9057 - val_loss: 1.5403 - val_accuracy: 0.7483\n","\n","Epoch 00038: val_loss did not improve from 0.73681\n","Epoch 39/50\n","1563/1563 [==============================] - 15s 9ms/step - loss: 0.3520 - accuracy: 0.9041 - val_loss: 1.3013 - val_accuracy: 0.7268\n","\n","Epoch 00039: val_loss did not improve from 0.73681\n","Epoch 40/50\n","1563/1563 [==============================] - 15s 9ms/step - loss: 0.3371 - accuracy: 0.9069 - val_loss: 1.4796 - val_accuracy: 0.7290\n","\n","Epoch 00040: val_loss did not improve from 0.73681\n","Epoch 41/50\n","1563/1563 [==============================] - 15s 10ms/step - loss: 0.3697 - accuracy: 0.9046 - val_loss: 1.4162 - val_accuracy: 0.7349\n","\n","Epoch 00041: val_loss did not improve from 0.73681\n","Epoch 42/50\n","1563/1563 [==============================] - 15s 9ms/step - loss: 0.3654 - accuracy: 0.9028 - val_loss: 1.7383 - val_accuracy: 0.7371\n","\n","Epoch 00042: val_loss did not improve from 0.73681\n","Epoch 43/50\n","1563/1563 [==============================] - 15s 10ms/step - loss: 0.3534 - accuracy: 0.9029 - val_loss: 1.4332 - val_accuracy: 0.7207\n","\n","Epoch 00043: val_loss did not improve from 0.73681\n","Epoch 44/50\n","1563/1563 [==============================] - 14s 9ms/step - loss: 0.3547 - accuracy: 0.9085 - val_loss: 1.2429 - val_accuracy: 0.6723\n","\n","Epoch 00044: val_loss did not improve from 0.73681\n","Epoch 45/50\n","1563/1563 [==============================] - 15s 10ms/step - loss: 0.3523 - accuracy: 0.9076 - val_loss: 1.5878 - val_accuracy: 0.7537\n","\n","Epoch 00045: val_loss did not improve from 0.73681\n","Epoch 46/50\n","1563/1563 [==============================] - 15s 10ms/step - loss: 0.3590 - accuracy: 0.9061 - val_loss: 1.6696 - val_accuracy: 0.7227\n","\n","Epoch 00046: val_loss did not improve from 0.73681\n","Epoch 47/50\n","1563/1563 [==============================] - 15s 10ms/step - loss: 0.3750 - accuracy: 0.9036 - val_loss: 1.6482 - val_accuracy: 0.7612\n","\n","Epoch 00047: val_loss did not improve from 0.73681\n","Epoch 48/50\n","1563/1563 [==============================] - 15s 9ms/step - loss: 0.4018 - accuracy: 0.9030 - val_loss: 1.9219 - val_accuracy: 0.7556\n","\n","Epoch 00048: val_loss did not improve from 0.73681\n","Epoch 49/50\n","1563/1563 [==============================] - 15s 9ms/step - loss: 0.3632 - accuracy: 0.9047 - val_loss: 1.5315 - val_accuracy: 0.7396\n","\n","Epoch 00049: val_loss did not improve from 0.73681\n","Epoch 50/50\n","1563/1563 [==============================] - 15s 10ms/step - loss: 0.3986 - accuracy: 0.9017 - val_loss: 1.5097 - val_accuracy: 0.7390\n","\n","Epoch 00050: val_loss did not improve from 0.73681\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"90b02193","executionInfo":{"status":"ok","timestamp":1626365310237,"user_tz":-330,"elapsed":15,"user":{"displayName":"ROHIT KUMAR","photoUrl":"","userId":"05114210246644333889"}},"outputId":"a497b786-52dd-441b-8311-db5504dcbc10"},"source":["## Model 2\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, GlobalAveragePooling2D\n","\n","# build the model object\n","model_2 = Sequential()\n","\n","# CONV_1: add CONV layer with RELU activation and depth = 32 kernels\n","model_2.add(Conv2D(32, kernel_size=(3, 3), padding='same',activation='elu',input_shape=(32,32,3)))\n","model_2.add(Conv2D(64, kernel_size=(3, 3),activation='elu',input_shape=(32,32,3)))\n","model_2.add(Conv2D(128, kernel_size=(3, 3), padding='same',activation='elu',input_shape=(32,32,3)))\n","# POOL_1: downsample the image to choose the best features \n","model_2.add(MaxPooling2D(pool_size=(2, 2)))\n","\n","# CONV_2: here we increase the depth to 64\n","model_2.add(Conv2D(64, (3, 3),padding='same', activation='elu'))\n","model_2.add(Conv2D(128, (3, 3),padding='same', activation='elu'))\n","# POOL_2: more downsampling\n","model_2.add(MaxPooling2D(pool_size=(2, 2)))\n","\n","# flatten since too many dimensions, we only want a classification output\n","model_2.add(Flatten())\n","\n","# FC_1: fully connected to get all relevant data\n","model_2.add(Dense(64, activation='relu'))\n","\n","# FC_2: output a softmax to squash the matrix into output probabilities for the 10 classes\n","model_2.add(Dense(10, activation='softmax'))\n","\n","model_2.summary()"],"id":"90b02193","execution_count":14,"outputs":[{"output_type":"stream","text":["Model: \"sequential_1\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","conv2d_5 (Conv2D)            (None, 32, 32, 32)        896       \n","_________________________________________________________________\n","conv2d_6 (Conv2D)            (None, 30, 30, 64)        18496     \n","_________________________________________________________________\n","conv2d_7 (Conv2D)            (None, 30, 30, 128)       73856     \n","_________________________________________________________________\n","max_pooling2d_2 (MaxPooling2 (None, 15, 15, 128)       0         \n","_________________________________________________________________\n","conv2d_8 (Conv2D)            (None, 15, 15, 64)        73792     \n","_________________________________________________________________\n","conv2d_9 (Conv2D)            (None, 15, 15, 128)       73856     \n","_________________________________________________________________\n","max_pooling2d_3 (MaxPooling2 (None, 7, 7, 128)         0         \n","_________________________________________________________________\n","flatten_1 (Flatten)          (None, 6272)              0         \n","_________________________________________________________________\n","dense_2 (Dense)              (None, 64)                401472    \n","_________________________________________________________________\n","dense_3 (Dense)              (None, 10)                650       \n","=================================================================\n","Total params: 643,018\n","Trainable params: 643,018\n","Non-trainable params: 0\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"a7d3e4c6","executionInfo":{"status":"ok","timestamp":1626366051174,"user_tz":-330,"elapsed":740941,"user":{"displayName":"ROHIT KUMAR","photoUrl":"","userId":"05114210246644333889"}},"outputId":"0067f2d2-cb3e-4793-8537-951e8a2f6a0e"},"source":["# compile the model\n","model_2.compile(loss='categorical_crossentropy', optimizer='adam', \n","              metrics=['accuracy'])\n","from tensorflow.keras.callbacks import ModelCheckpoint   \n","\n","# train the model\n","checkpointer = ModelCheckpoint(filepath='model_2.weights.best.hdf5', verbose=1, \n","                               save_best_only=True)\n","hist = model_2.fit(X_train, y_train, batch_size=32, epochs=50,\n","          validation_data=(X_test, y_test), callbacks=[checkpointer], \n","          verbose=1, shuffle=True)"],"id":"a7d3e4c6","execution_count":15,"outputs":[{"output_type":"stream","text":["Epoch 1/50\n","1563/1563 [==============================] - 16s 10ms/step - loss: 1.2762 - accuracy: 0.5513 - val_loss: 1.1051 - val_accuracy: 0.6157\n","\n","Epoch 00001: val_loss improved from inf to 1.10505, saving model to model_2.weights.best.hdf5\n","Epoch 2/50\n","1563/1563 [==============================] - 15s 10ms/step - loss: 0.9309 - accuracy: 0.6753 - val_loss: 0.8832 - val_accuracy: 0.6972\n","\n","Epoch 00002: val_loss improved from 1.10505 to 0.88317, saving model to model_2.weights.best.hdf5\n","Epoch 3/50\n","1563/1563 [==============================] - 15s 10ms/step - loss: 0.7814 - accuracy: 0.7282 - val_loss: 0.8254 - val_accuracy: 0.7228\n","\n","Epoch 00003: val_loss improved from 0.88317 to 0.82538, saving model to model_2.weights.best.hdf5\n","Epoch 4/50\n","1563/1563 [==============================] - 15s 10ms/step - loss: 0.6658 - accuracy: 0.7693 - val_loss: 0.8666 - val_accuracy: 0.7136\n","\n","Epoch 00004: val_loss did not improve from 0.82538\n","Epoch 5/50\n","1563/1563 [==============================] - 15s 9ms/step - loss: 0.5474 - accuracy: 0.8081 - val_loss: 0.8580 - val_accuracy: 0.7348\n","\n","Epoch 00005: val_loss did not improve from 0.82538\n","Epoch 6/50\n","1563/1563 [==============================] - 15s 10ms/step - loss: 0.4504 - accuracy: 0.8430 - val_loss: 0.9052 - val_accuracy: 0.7275\n","\n","Epoch 00006: val_loss did not improve from 0.82538\n","Epoch 7/50\n","1563/1563 [==============================] - 15s 10ms/step - loss: 0.3751 - accuracy: 0.8676 - val_loss: 0.9522 - val_accuracy: 0.7322\n","\n","Epoch 00007: val_loss did not improve from 0.82538\n","Epoch 8/50\n","1563/1563 [==============================] - 15s 9ms/step - loss: 0.3197 - accuracy: 0.8886 - val_loss: 1.1252 - val_accuracy: 0.7252\n","\n","Epoch 00008: val_loss did not improve from 0.82538\n","Epoch 9/50\n","1563/1563 [==============================] - 15s 9ms/step - loss: 0.2722 - accuracy: 0.9057 - val_loss: 1.1222 - val_accuracy: 0.7269\n","\n","Epoch 00009: val_loss did not improve from 0.82538\n","Epoch 10/50\n","1563/1563 [==============================] - 15s 10ms/step - loss: 0.2396 - accuracy: 0.9178 - val_loss: 1.2100 - val_accuracy: 0.7353\n","\n","Epoch 00010: val_loss did not improve from 0.82538\n","Epoch 11/50\n","1563/1563 [==============================] - 15s 10ms/step - loss: 0.2222 - accuracy: 0.9238 - val_loss: 1.5115 - val_accuracy: 0.7208\n","\n","Epoch 00011: val_loss did not improve from 0.82538\n","Epoch 12/50\n","1563/1563 [==============================] - 15s 9ms/step - loss: 0.1976 - accuracy: 0.9336 - val_loss: 1.4666 - val_accuracy: 0.7380\n","\n","Epoch 00012: val_loss did not improve from 0.82538\n","Epoch 13/50\n","1563/1563 [==============================] - 15s 9ms/step - loss: 0.1868 - accuracy: 0.9386 - val_loss: 1.4222 - val_accuracy: 0.7225\n","\n","Epoch 00013: val_loss did not improve from 0.82538\n","Epoch 14/50\n","1563/1563 [==============================] - 15s 9ms/step - loss: 0.1819 - accuracy: 0.9408 - val_loss: 1.5008 - val_accuracy: 0.7313\n","\n","Epoch 00014: val_loss did not improve from 0.82538\n","Epoch 15/50\n","1563/1563 [==============================] - 15s 10ms/step - loss: 0.2740 - accuracy: 0.9191 - val_loss: 2.3318 - val_accuracy: 0.0996\n","\n","Epoch 00015: val_loss did not improve from 0.82538\n","Epoch 16/50\n","1563/1563 [==============================] - 15s 9ms/step - loss: 2.3063 - accuracy: 0.1015 - val_loss: 2.3027 - val_accuracy: 0.1000\n","\n","Epoch 00016: val_loss did not improve from 0.82538\n","Epoch 17/50\n","1563/1563 [==============================] - 15s 9ms/step - loss: 2.3028 - accuracy: 0.0971 - val_loss: 2.3026 - val_accuracy: 0.1000\n","\n","Epoch 00017: val_loss did not improve from 0.82538\n","Epoch 18/50\n","1563/1563 [==============================] - 15s 10ms/step - loss: 2.3028 - accuracy: 0.0980 - val_loss: 2.3027 - val_accuracy: 0.1000\n","\n","Epoch 00018: val_loss did not improve from 0.82538\n","Epoch 19/50\n","1563/1563 [==============================] - 15s 9ms/step - loss: 2.3028 - accuracy: 0.0969 - val_loss: 2.3026 - val_accuracy: 0.1000\n","\n","Epoch 00019: val_loss did not improve from 0.82538\n","Epoch 20/50\n","1563/1563 [==============================] - 15s 9ms/step - loss: 2.3028 - accuracy: 0.0971 - val_loss: 2.3026 - val_accuracy: 0.1000\n","\n","Epoch 00020: val_loss did not improve from 0.82538\n","Epoch 21/50\n","1563/1563 [==============================] - 15s 9ms/step - loss: 2.3028 - accuracy: 0.0964 - val_loss: 2.3027 - val_accuracy: 0.1000\n","\n","Epoch 00021: val_loss did not improve from 0.82538\n","Epoch 22/50\n","1563/1563 [==============================] - 15s 10ms/step - loss: 2.3028 - accuracy: 0.0988 - val_loss: 2.3026 - val_accuracy: 0.1000\n","\n","Epoch 00022: val_loss did not improve from 0.82538\n","Epoch 23/50\n","1563/1563 [==============================] - 15s 9ms/step - loss: 2.3028 - accuracy: 0.0993 - val_loss: 2.3026 - val_accuracy: 0.1000\n","\n","Epoch 00023: val_loss did not improve from 0.82538\n","Epoch 24/50\n","1563/1563 [==============================] - 15s 9ms/step - loss: 2.3028 - accuracy: 0.0970 - val_loss: 2.3027 - val_accuracy: 0.1000\n","\n","Epoch 00024: val_loss did not improve from 0.82538\n","Epoch 25/50\n","1563/1563 [==============================] - 15s 9ms/step - loss: 2.3027 - accuracy: 0.1000 - val_loss: 2.3027 - val_accuracy: 0.1000\n","\n","Epoch 00025: val_loss did not improve from 0.82538\n","Epoch 26/50\n","1563/1563 [==============================] - 15s 10ms/step - loss: 2.3028 - accuracy: 0.0982 - val_loss: 2.3026 - val_accuracy: 0.1000\n","\n","Epoch 00026: val_loss did not improve from 0.82538\n","Epoch 27/50\n","1563/1563 [==============================] - 15s 9ms/step - loss: 2.3028 - accuracy: 0.0991 - val_loss: 2.3026 - val_accuracy: 0.1000\n","\n","Epoch 00027: val_loss did not improve from 0.82538\n","Epoch 28/50\n","1563/1563 [==============================] - 15s 9ms/step - loss: 2.3028 - accuracy: 0.0980 - val_loss: 2.3026 - val_accuracy: 0.1000\n","\n","Epoch 00028: val_loss did not improve from 0.82538\n","Epoch 29/50\n","1563/1563 [==============================] - 14s 9ms/step - loss: 2.3028 - accuracy: 0.0982 - val_loss: 2.3026 - val_accuracy: 0.1000\n","\n","Epoch 00029: val_loss did not improve from 0.82538\n","Epoch 30/50\n","1563/1563 [==============================] - 15s 9ms/step - loss: 2.3028 - accuracy: 0.0982 - val_loss: 2.3026 - val_accuracy: 0.1000\n","\n","Epoch 00030: val_loss did not improve from 0.82538\n","Epoch 31/50\n","1563/1563 [==============================] - 15s 9ms/step - loss: 2.3028 - accuracy: 0.0999 - val_loss: 2.3027 - val_accuracy: 0.1000\n","\n","Epoch 00031: val_loss did not improve from 0.82538\n","Epoch 32/50\n","1563/1563 [==============================] - 15s 9ms/step - loss: 2.3028 - accuracy: 0.0965 - val_loss: 2.3026 - val_accuracy: 0.1000\n","\n","Epoch 00032: val_loss did not improve from 0.82538\n","Epoch 33/50\n","1563/1563 [==============================] - 15s 9ms/step - loss: 2.3028 - accuracy: 0.0989 - val_loss: 2.3026 - val_accuracy: 0.1000\n","\n","Epoch 00033: val_loss did not improve from 0.82538\n","Epoch 34/50\n","1563/1563 [==============================] - 14s 9ms/step - loss: 2.3028 - accuracy: 0.0986 - val_loss: 2.3026 - val_accuracy: 0.1000\n","\n","Epoch 00034: val_loss did not improve from 0.82538\n","Epoch 35/50\n","1563/1563 [==============================] - 15s 10ms/step - loss: 2.3028 - accuracy: 0.0962 - val_loss: 2.3026 - val_accuracy: 0.1000\n","\n","Epoch 00035: val_loss did not improve from 0.82538\n","Epoch 36/50\n","1563/1563 [==============================] - 15s 9ms/step - loss: 2.3028 - accuracy: 0.0982 - val_loss: 2.3027 - val_accuracy: 0.1000\n","\n","Epoch 00036: val_loss did not improve from 0.82538\n","Epoch 37/50\n","1563/1563 [==============================] - 15s 9ms/step - loss: 2.3028 - accuracy: 0.0984 - val_loss: 2.3026 - val_accuracy: 0.1000\n","\n","Epoch 00037: val_loss did not improve from 0.82538\n","Epoch 38/50\n","1563/1563 [==============================] - 15s 9ms/step - loss: 2.3028 - accuracy: 0.0980 - val_loss: 2.3026 - val_accuracy: 0.1000\n","\n","Epoch 00038: val_loss did not improve from 0.82538\n","Epoch 39/50\n","1563/1563 [==============================] - 15s 10ms/step - loss: 2.3028 - accuracy: 0.0981 - val_loss: 2.3026 - val_accuracy: 0.1000\n","\n","Epoch 00039: val_loss did not improve from 0.82538\n","Epoch 40/50\n","1563/1563 [==============================] - 15s 10ms/step - loss: 2.3028 - accuracy: 0.1004 - val_loss: 2.3027 - val_accuracy: 0.1000\n","\n","Epoch 00040: val_loss did not improve from 0.82538\n","Epoch 41/50\n","1563/1563 [==============================] - 15s 9ms/step - loss: 2.3028 - accuracy: 0.0963 - val_loss: 2.3027 - val_accuracy: 0.1000\n","\n","Epoch 00041: val_loss did not improve from 0.82538\n","Epoch 42/50\n","1563/1563 [==============================] - 15s 10ms/step - loss: 2.3028 - accuracy: 0.0967 - val_loss: 2.3026 - val_accuracy: 0.1000\n","\n","Epoch 00042: val_loss did not improve from 0.82538\n","Epoch 43/50\n","1563/1563 [==============================] - 15s 9ms/step - loss: 2.3028 - accuracy: 0.0993 - val_loss: 2.3026 - val_accuracy: 0.1000\n","\n","Epoch 00043: val_loss did not improve from 0.82538\n","Epoch 44/50\n","1563/1563 [==============================] - 15s 9ms/step - loss: 2.3028 - accuracy: 0.0973 - val_loss: 2.3026 - val_accuracy: 0.1000\n","\n","Epoch 00044: val_loss did not improve from 0.82538\n","Epoch 45/50\n","1563/1563 [==============================] - 15s 9ms/step - loss: 2.3028 - accuracy: 0.0976 - val_loss: 2.3026 - val_accuracy: 0.1000\n","\n","Epoch 00045: val_loss did not improve from 0.82538\n","Epoch 46/50\n","1563/1563 [==============================] - 15s 9ms/step - loss: 2.3028 - accuracy: 0.0976 - val_loss: 2.3026 - val_accuracy: 0.1000\n","\n","Epoch 00046: val_loss did not improve from 0.82538\n","Epoch 47/50\n","1563/1563 [==============================] - 15s 9ms/step - loss: 2.3028 - accuracy: 0.0976 - val_loss: 2.3026 - val_accuracy: 0.1000\n","\n","Epoch 00047: val_loss did not improve from 0.82538\n","Epoch 48/50\n","1563/1563 [==============================] - 15s 9ms/step - loss: 2.3028 - accuracy: 0.0983 - val_loss: 2.3026 - val_accuracy: 0.1000\n","\n","Epoch 00048: val_loss did not improve from 0.82538\n","Epoch 49/50\n","1563/1563 [==============================] - 14s 9ms/step - loss: 2.3028 - accuracy: 0.0983 - val_loss: 2.3026 - val_accuracy: 0.1000\n","\n","Epoch 00049: val_loss did not improve from 0.82538\n","Epoch 50/50\n","1563/1563 [==============================] - 15s 9ms/step - loss: 2.3028 - accuracy: 0.0979 - val_loss: 2.3026 - val_accuracy: 0.1000\n","\n","Epoch 00050: val_loss did not improve from 0.82538\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"h2FNB4_K16a4","executionInfo":{"status":"ok","timestamp":1626366051175,"user_tz":-330,"elapsed":15,"user":{"displayName":"ROHIT KUMAR","photoUrl":"","userId":"05114210246644333889"}},"outputId":"769ae810-1675-473d-ae76-bef1acd7043d"},"source":["## Model 3\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, GlobalAveragePooling2D\n","\n","# build the model object\n","model_3 = Sequential()\n","\n","# CONV_1: add CONV layer with RELU activation and depth = 32 kernels\n","model_3.add(Conv2D(32, kernel_size=(5, 5), padding='same',activation='elu',input_shape=(32,32,3)))\n","model_3.add(Conv2D(64, kernel_size=(3, 3),activation='elu',input_shape=(32,32,3)))\n","model_3.add(Conv2D(128, kernel_size=(3, 3),activation='elu',input_shape=(32,32,3)))\n","# POOL_1: downsample the image to choose the best features \n","model_3.add(MaxPooling2D(pool_size=(2, 2)))\n","\n","# CONV_2: here we increase the depth to 64\n","model_3.add(Conv2D(64, (3, 3),padding='same', activation='elu'))\n","model_3.add(Conv2D(128, (3, 3), activation='elu'))\n","# POOL_2: more downsampling\n","model_3.add(MaxPooling2D(pool_size=(2, 2)))\n","\n","# flatten since too many dimensions, we only want a classification output\n","model_3.add(Flatten())\n","\n","# FC_1: fully connected to get all relevant data\n","model_3.add(Dense(64, activation='elu'))\n","\n","# FC_2: output a softmax to squash the matrix into output probabilities for the 10 classes\n","model_3.add(Dense(10, activation='softmax'))\n","\n","model_3.summary()"],"id":"h2FNB4_K16a4","execution_count":16,"outputs":[{"output_type":"stream","text":["Model: \"sequential_2\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","conv2d_10 (Conv2D)           (None, 32, 32, 32)        2432      \n","_________________________________________________________________\n","conv2d_11 (Conv2D)           (None, 30, 30, 64)        18496     \n","_________________________________________________________________\n","conv2d_12 (Conv2D)           (None, 28, 28, 128)       73856     \n","_________________________________________________________________\n","max_pooling2d_4 (MaxPooling2 (None, 14, 14, 128)       0         \n","_________________________________________________________________\n","conv2d_13 (Conv2D)           (None, 14, 14, 64)        73792     \n","_________________________________________________________________\n","conv2d_14 (Conv2D)           (None, 12, 12, 128)       73856     \n","_________________________________________________________________\n","max_pooling2d_5 (MaxPooling2 (None, 6, 6, 128)         0         \n","_________________________________________________________________\n","flatten_2 (Flatten)          (None, 4608)              0         \n","_________________________________________________________________\n","dense_4 (Dense)              (None, 64)                294976    \n","_________________________________________________________________\n","dense_5 (Dense)              (None, 10)                650       \n","=================================================================\n","Total params: 538,058\n","Trainable params: 538,058\n","Non-trainable params: 0\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DLIFlvRV2Cff","executionInfo":{"status":"ok","timestamp":1626366794246,"user_tz":-330,"elapsed":743075,"user":{"displayName":"ROHIT KUMAR","photoUrl":"","userId":"05114210246644333889"}},"outputId":"c36052ec-3df6-4404-bff5-4da4b2c93f15"},"source":["# compile the model\n","model_3.compile(loss='categorical_crossentropy', optimizer='rmsprop', \n","              metrics=['accuracy'])\n","from tensorflow.keras.callbacks import ModelCheckpoint   \n","\n","# train the model\n","checkpointer = ModelCheckpoint(filepath='model_3.weights.best.hdf5', verbose=1, \n","                               save_best_only=True)\n","hist = model_3.fit(X_train, y_train, batch_size=32, epochs=50,\n","          validation_data=(X_test, y_test), callbacks=[checkpointer], \n","          verbose=1, shuffle=True)"],"id":"DLIFlvRV2Cff","execution_count":17,"outputs":[{"output_type":"stream","text":["Epoch 1/50\n","1563/1563 [==============================] - 16s 9ms/step - loss: 1.4367 - accuracy: 0.5042 - val_loss: 1.1761 - val_accuracy: 0.5950\n","\n","Epoch 00001: val_loss improved from inf to 1.17608, saving model to model_3.weights.best.hdf5\n","Epoch 2/50\n","1563/1563 [==============================] - 14s 9ms/step - loss: 0.9814 - accuracy: 0.6621 - val_loss: 1.0532 - val_accuracy: 0.6484\n","\n","Epoch 00002: val_loss improved from 1.17608 to 1.05325, saving model to model_3.weights.best.hdf5\n","Epoch 3/50\n","1563/1563 [==============================] - 14s 9ms/step - loss: 0.8236 - accuracy: 0.7184 - val_loss: 0.9176 - val_accuracy: 0.6876\n","\n","Epoch 00003: val_loss improved from 1.05325 to 0.91760, saving model to model_3.weights.best.hdf5\n","Epoch 4/50\n","1563/1563 [==============================] - 14s 9ms/step - loss: 0.7132 - accuracy: 0.7573 - val_loss: 1.0757 - val_accuracy: 0.6757\n","\n","Epoch 00004: val_loss did not improve from 0.91760\n","Epoch 5/50\n","1563/1563 [==============================] - 14s 9ms/step - loss: 0.6115 - accuracy: 0.7924 - val_loss: 0.9663 - val_accuracy: 0.6980\n","\n","Epoch 00005: val_loss did not improve from 0.91760\n","Epoch 6/50\n","1563/1563 [==============================] - 15s 9ms/step - loss: 0.5211 - accuracy: 0.8228 - val_loss: 1.0648 - val_accuracy: 0.7022\n","\n","Epoch 00006: val_loss did not improve from 0.91760\n","Epoch 7/50\n","1563/1563 [==============================] - 14s 9ms/step - loss: 0.4615 - accuracy: 0.8435 - val_loss: 1.3531 - val_accuracy: 0.7090\n","\n","Epoch 00007: val_loss did not improve from 0.91760\n","Epoch 8/50\n","1563/1563 [==============================] - 14s 9ms/step - loss: 0.4057 - accuracy: 0.8666 - val_loss: 1.5165 - val_accuracy: 0.6536\n","\n","Epoch 00008: val_loss did not improve from 0.91760\n","Epoch 9/50\n","1563/1563 [==============================] - 14s 9ms/step - loss: 0.3682 - accuracy: 0.8792 - val_loss: 1.4652 - val_accuracy: 0.7025\n","\n","Epoch 00009: val_loss did not improve from 0.91760\n","Epoch 10/50\n","1563/1563 [==============================] - 14s 9ms/step - loss: 0.3352 - accuracy: 0.8930 - val_loss: 1.6522 - val_accuracy: 0.6941\n","\n","Epoch 00010: val_loss did not improve from 0.91760\n","Epoch 11/50\n","1563/1563 [==============================] - 14s 9ms/step - loss: 0.3210 - accuracy: 0.8998 - val_loss: 1.6589 - val_accuracy: 0.7029\n","\n","Epoch 00011: val_loss did not improve from 0.91760\n","Epoch 12/50\n","1563/1563 [==============================] - 15s 9ms/step - loss: 0.3051 - accuracy: 0.9089 - val_loss: 1.9792 - val_accuracy: 0.7079\n","\n","Epoch 00012: val_loss did not improve from 0.91760\n","Epoch 13/50\n","1563/1563 [==============================] - 15s 9ms/step - loss: 0.2928 - accuracy: 0.9123 - val_loss: 1.9148 - val_accuracy: 0.6856\n","\n","Epoch 00013: val_loss did not improve from 0.91760\n","Epoch 14/50\n","1563/1563 [==============================] - 14s 9ms/step - loss: 0.2698 - accuracy: 0.9218 - val_loss: 2.4859 - val_accuracy: 0.6934\n","\n","Epoch 00014: val_loss did not improve from 0.91760\n","Epoch 15/50\n","1563/1563 [==============================] - 14s 9ms/step - loss: 0.2764 - accuracy: 0.9214 - val_loss: 2.0817 - val_accuracy: 0.7003\n","\n","Epoch 00015: val_loss did not improve from 0.91760\n","Epoch 16/50\n","1563/1563 [==============================] - 14s 9ms/step - loss: 0.2604 - accuracy: 0.9271 - val_loss: 2.5313 - val_accuracy: 0.7000\n","\n","Epoch 00016: val_loss did not improve from 0.91760\n","Epoch 17/50\n","1563/1563 [==============================] - 14s 9ms/step - loss: 0.2627 - accuracy: 0.9294 - val_loss: 1.9183 - val_accuracy: 0.6566\n","\n","Epoch 00017: val_loss did not improve from 0.91760\n","Epoch 18/50\n","1563/1563 [==============================] - 14s 9ms/step - loss: 0.2608 - accuracy: 0.9301 - val_loss: 2.5698 - val_accuracy: 0.6894\n","\n","Epoch 00018: val_loss did not improve from 0.91760\n","Epoch 19/50\n","1563/1563 [==============================] - 14s 9ms/step - loss: 0.2536 - accuracy: 0.9324 - val_loss: 3.2299 - val_accuracy: 0.7070\n","\n","Epoch 00019: val_loss did not improve from 0.91760\n","Epoch 20/50\n","1563/1563 [==============================] - 14s 9ms/step - loss: 0.2646 - accuracy: 0.9334 - val_loss: 3.2087 - val_accuracy: 0.6985\n","\n","Epoch 00020: val_loss did not improve from 0.91760\n","Epoch 21/50\n","1563/1563 [==============================] - 14s 9ms/step - loss: 0.2561 - accuracy: 0.9373 - val_loss: 2.4176 - val_accuracy: 0.6879\n","\n","Epoch 00021: val_loss did not improve from 0.91760\n","Epoch 22/50\n","1563/1563 [==============================] - 15s 9ms/step - loss: 0.2471 - accuracy: 0.9380 - val_loss: 3.2366 - val_accuracy: 0.7077\n","\n","Epoch 00022: val_loss did not improve from 0.91760\n","Epoch 23/50\n","1563/1563 [==============================] - 14s 9ms/step - loss: 0.2584 - accuracy: 0.9383 - val_loss: 3.8041 - val_accuracy: 0.6975\n","\n","Epoch 00023: val_loss did not improve from 0.91760\n","Epoch 24/50\n","1563/1563 [==============================] - 14s 9ms/step - loss: 0.2540 - accuracy: 0.9409 - val_loss: 3.4249 - val_accuracy: 0.6676\n","\n","Epoch 00024: val_loss did not improve from 0.91760\n","Epoch 25/50\n","1563/1563 [==============================] - 14s 9ms/step - loss: 0.2484 - accuracy: 0.9425 - val_loss: 3.0031 - val_accuracy: 0.6946\n","\n","Epoch 00025: val_loss did not improve from 0.91760\n","Epoch 26/50\n","1563/1563 [==============================] - 15s 9ms/step - loss: 0.2500 - accuracy: 0.9422 - val_loss: 4.6168 - val_accuracy: 0.6726\n","\n","Epoch 00026: val_loss did not improve from 0.91760\n","Epoch 27/50\n","1563/1563 [==============================] - 14s 9ms/step - loss: 0.2644 - accuracy: 0.9420 - val_loss: 3.0923 - val_accuracy: 0.6913\n","\n","Epoch 00027: val_loss did not improve from 0.91760\n","Epoch 28/50\n","1563/1563 [==============================] - 14s 9ms/step - loss: 0.2516 - accuracy: 0.9453 - val_loss: 3.7396 - val_accuracy: 0.6948\n","\n","Epoch 00028: val_loss did not improve from 0.91760\n","Epoch 29/50\n","1563/1563 [==============================] - 14s 9ms/step - loss: 0.2649 - accuracy: 0.9455 - val_loss: 4.0680 - val_accuracy: 0.7008\n","\n","Epoch 00029: val_loss did not improve from 0.91760\n","Epoch 30/50\n","1563/1563 [==============================] - 14s 9ms/step - loss: 0.2764 - accuracy: 0.9428 - val_loss: 3.6321 - val_accuracy: 0.6970\n","\n","Epoch 00030: val_loss did not improve from 0.91760\n","Epoch 31/50\n","1563/1563 [==============================] - 15s 9ms/step - loss: 0.2521 - accuracy: 0.9458 - val_loss: 3.6863 - val_accuracy: 0.6968\n","\n","Epoch 00031: val_loss did not improve from 0.91760\n","Epoch 32/50\n","1563/1563 [==============================] - 14s 9ms/step - loss: 0.2684 - accuracy: 0.9465 - val_loss: 3.9150 - val_accuracy: 0.7003\n","\n","Epoch 00032: val_loss did not improve from 0.91760\n","Epoch 33/50\n","1563/1563 [==============================] - 14s 9ms/step - loss: 0.2723 - accuracy: 0.9489 - val_loss: 4.0578 - val_accuracy: 0.6846\n","\n","Epoch 00033: val_loss did not improve from 0.91760\n","Epoch 34/50\n","1563/1563 [==============================] - 14s 9ms/step - loss: 0.2590 - accuracy: 0.9510 - val_loss: 4.0014 - val_accuracy: 0.6771\n","\n","Epoch 00034: val_loss did not improve from 0.91760\n","Epoch 35/50\n","1563/1563 [==============================] - 14s 9ms/step - loss: 0.2650 - accuracy: 0.9523 - val_loss: 4.4426 - val_accuracy: 0.7033\n","\n","Epoch 00035: val_loss did not improve from 0.91760\n","Epoch 36/50\n","1563/1563 [==============================] - 14s 9ms/step - loss: 0.2778 - accuracy: 0.9496 - val_loss: 4.6276 - val_accuracy: 0.6979\n","\n","Epoch 00036: val_loss did not improve from 0.91760\n","Epoch 37/50\n","1563/1563 [==============================] - 14s 9ms/step - loss: 0.2710 - accuracy: 0.9514 - val_loss: 4.3599 - val_accuracy: 0.6973\n","\n","Epoch 00037: val_loss did not improve from 0.91760\n","Epoch 38/50\n","1563/1563 [==============================] - 14s 9ms/step - loss: 0.2859 - accuracy: 0.9514 - val_loss: 3.7346 - val_accuracy: 0.6800\n","\n","Epoch 00038: val_loss did not improve from 0.91760\n","Epoch 39/50\n","1563/1563 [==============================] - 14s 9ms/step - loss: 0.2977 - accuracy: 0.9495 - val_loss: 4.9932 - val_accuracy: 0.6978\n","\n","Epoch 00039: val_loss did not improve from 0.91760\n","Epoch 40/50\n","1563/1563 [==============================] - 14s 9ms/step - loss: 0.2844 - accuracy: 0.9536 - val_loss: 4.7136 - val_accuracy: 0.6911\n","\n","Epoch 00040: val_loss did not improve from 0.91760\n","Epoch 41/50\n","1563/1563 [==============================] - 14s 9ms/step - loss: 0.2924 - accuracy: 0.9541 - val_loss: 5.8706 - val_accuracy: 0.6847\n","\n","Epoch 00041: val_loss did not improve from 0.91760\n","Epoch 42/50\n","1563/1563 [==============================] - 15s 9ms/step - loss: 0.2975 - accuracy: 0.9549 - val_loss: 6.3869 - val_accuracy: 0.6925\n","\n","Epoch 00042: val_loss did not improve from 0.91760\n","Epoch 43/50\n","1563/1563 [==============================] - 15s 9ms/step - loss: 0.3002 - accuracy: 0.9541 - val_loss: 5.5829 - val_accuracy: 0.6940\n","\n","Epoch 00043: val_loss did not improve from 0.91760\n","Epoch 44/50\n","1563/1563 [==============================] - 14s 9ms/step - loss: 0.2939 - accuracy: 0.9568 - val_loss: 5.2109 - val_accuracy: 0.6558\n","\n","Epoch 00044: val_loss did not improve from 0.91760\n","Epoch 45/50\n","1563/1563 [==============================] - 14s 9ms/step - loss: 0.3118 - accuracy: 0.9540 - val_loss: 5.9830 - val_accuracy: 0.7012\n","\n","Epoch 00045: val_loss did not improve from 0.91760\n","Epoch 46/50\n","1563/1563 [==============================] - 14s 9ms/step - loss: 0.3322 - accuracy: 0.9550 - val_loss: 6.5090 - val_accuracy: 0.6997\n","\n","Epoch 00046: val_loss did not improve from 0.91760\n","Epoch 47/50\n","1563/1563 [==============================] - 14s 9ms/step - loss: 0.3160 - accuracy: 0.9578 - val_loss: 6.2642 - val_accuracy: 0.6950\n","\n","Epoch 00047: val_loss did not improve from 0.91760\n","Epoch 48/50\n","1563/1563 [==============================] - 15s 9ms/step - loss: 0.3237 - accuracy: 0.9574 - val_loss: 7.3569 - val_accuracy: 0.6987\n","\n","Epoch 00048: val_loss did not improve from 0.91760\n","Epoch 49/50\n","1563/1563 [==============================] - 14s 9ms/step - loss: 0.3422 - accuracy: 0.9573 - val_loss: 7.4689 - val_accuracy: 0.7044\n","\n","Epoch 00049: val_loss did not improve from 0.91760\n","Epoch 50/50\n","1563/1563 [==============================] - 14s 9ms/step - loss: 0.3320 - accuracy: 0.9588 - val_loss: 7.0736 - val_accuracy: 0.6779\n","\n","Epoch 00050: val_loss did not improve from 0.91760\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ba_ewQqN2h94","executionInfo":{"status":"ok","timestamp":1626366794249,"user_tz":-330,"elapsed":6,"user":{"displayName":"ROHIT KUMAR","photoUrl":"","userId":"05114210246644333889"}},"outputId":"16eed0c7-9a86-4a17-f5fe-8e29b6c164e9"},"source":["## Model 4\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, GlobalAveragePooling2D\n","\n","# build the model object\n","model_4 = Sequential()\n","\n","# CONV_1: add CONV layer with RELU activation and depth = 32 kernels\n","model_4.add(Conv2D(32, kernel_size=(5, 5), padding='same',activation='selu',input_shape=(32,32,3)))\n","model_4.add(Conv2D(64, kernel_size=(3, 3), padding='same',activation='selu',input_shape=(32,32,3)))\n","model_4.add(Conv2D(128, kernel_size=(3, 3), padding='same',activation='selu',input_shape=(32,32,3)))\n","# POOL_1: downsample the image to choose the best features \n","model_4.add(MaxPooling2D(pool_size=(2, 2)))\n","\n","# CONV_2: here we increase the depth to 64\n","model_4.add(Conv2D(64, (3, 3),padding='same', activation='selu'))\n","model_4.add(Conv2D(128, (3, 3), activation='selu'))\n","# POOL_2: more downsampling\n","model_4.add(MaxPooling2D(pool_size=(2, 2)))\n","\n","# flatten since too many dimensions, we only want a classification output\n","model_4.add(Flatten())\n","\n","# FC_1: fully connected to get all relevant data\n","model_4.add(Dense(64, activation='selu'))\n","\n","# FC_2: output a softmax to squash the matrix into output probabilities for the 10 classes\n","model_4.add(Dense(10, activation='softmax'))\n","\n","model_4.summary()"],"id":"ba_ewQqN2h94","execution_count":18,"outputs":[{"output_type":"stream","text":["Model: \"sequential_3\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","conv2d_15 (Conv2D)           (None, 32, 32, 32)        2432      \n","_________________________________________________________________\n","conv2d_16 (Conv2D)           (None, 32, 32, 64)        18496     \n","_________________________________________________________________\n","conv2d_17 (Conv2D)           (None, 32, 32, 128)       73856     \n","_________________________________________________________________\n","max_pooling2d_6 (MaxPooling2 (None, 16, 16, 128)       0         \n","_________________________________________________________________\n","conv2d_18 (Conv2D)           (None, 16, 16, 64)        73792     \n","_________________________________________________________________\n","conv2d_19 (Conv2D)           (None, 14, 14, 128)       73856     \n","_________________________________________________________________\n","max_pooling2d_7 (MaxPooling2 (None, 7, 7, 128)         0         \n","_________________________________________________________________\n","flatten_3 (Flatten)          (None, 6272)              0         \n","_________________________________________________________________\n","dense_6 (Dense)              (None, 64)                401472    \n","_________________________________________________________________\n","dense_7 (Dense)              (None, 10)                650       \n","=================================================================\n","Total params: 644,554\n","Trainable params: 644,554\n","Non-trainable params: 0\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1UqoXEoI2_qp","executionInfo":{"status":"ok","timestamp":1626367562697,"user_tz":-330,"elapsed":768452,"user":{"displayName":"ROHIT KUMAR","photoUrl":"","userId":"05114210246644333889"}},"outputId":"a2ca81d0-f847-4ffc-e40d-8e655e9e1ef5"},"source":["# compile the model\n","model_4.compile(loss='categorical_crossentropy', optimizer='rmsprop', \n","              metrics=['accuracy'])\n","from tensorflow.keras.callbacks import ModelCheckpoint   \n","\n","# train the model\n","checkpointer = ModelCheckpoint(filepath='model_4.weights.best.hdf5', verbose=1, \n","                               save_best_only=True)\n","hist = model_4.fit(X_train, y_train, batch_size=32, epochs=50,\n","          validation_data=(X_test, y_test), callbacks=[checkpointer], \n","          verbose=1, shuffle=True)"],"id":"1UqoXEoI2_qp","execution_count":19,"outputs":[{"output_type":"stream","text":["Epoch 1/50\n","1563/1563 [==============================] - 16s 10ms/step - loss: 2.2041 - accuracy: 0.4103 - val_loss: 1.3500 - val_accuracy: 0.5465\n","\n","Epoch 00001: val_loss improved from inf to 1.35004, saving model to model_4.weights.best.hdf5\n","Epoch 2/50\n","1563/1563 [==============================] - 15s 10ms/step - loss: 1.1966 - accuracy: 0.5960 - val_loss: 1.1736 - val_accuracy: 0.6159\n","\n","Epoch 00002: val_loss improved from 1.35004 to 1.17364, saving model to model_4.weights.best.hdf5\n","Epoch 3/50\n","1563/1563 [==============================] - 15s 10ms/step - loss: 1.0415 - accuracy: 0.6492 - val_loss: 1.0542 - val_accuracy: 0.6449\n","\n","Epoch 00003: val_loss improved from 1.17364 to 1.05421, saving model to model_4.weights.best.hdf5\n","Epoch 4/50\n","1563/1563 [==============================] - 16s 10ms/step - loss: 0.9213 - accuracy: 0.6866 - val_loss: 1.3471 - val_accuracy: 0.5849\n","\n","Epoch 00004: val_loss did not improve from 1.05421\n","Epoch 5/50\n","1563/1563 [==============================] - 15s 10ms/step - loss: 0.8204 - accuracy: 0.7237 - val_loss: 1.3406 - val_accuracy: 0.6138\n","\n","Epoch 00005: val_loss did not improve from 1.05421\n","Epoch 6/50\n","1563/1563 [==============================] - 16s 10ms/step - loss: 0.7347 - accuracy: 0.7530 - val_loss: 1.1833 - val_accuracy: 0.6473\n","\n","Epoch 00006: val_loss did not improve from 1.05421\n","Epoch 7/50\n","1563/1563 [==============================] - 15s 10ms/step - loss: 0.6657 - accuracy: 0.7776 - val_loss: 1.3273 - val_accuracy: 0.6350\n","\n","Epoch 00007: val_loss did not improve from 1.05421\n","Epoch 8/50\n","1563/1563 [==============================] - 15s 10ms/step - loss: 0.5991 - accuracy: 0.7987 - val_loss: 1.2602 - val_accuracy: 0.6631\n","\n","Epoch 00008: val_loss did not improve from 1.05421\n","Epoch 9/50\n","1563/1563 [==============================] - 15s 10ms/step - loss: 0.5473 - accuracy: 0.8198 - val_loss: 1.5883 - val_accuracy: 0.6378\n","\n","Epoch 00009: val_loss did not improve from 1.05421\n","Epoch 10/50\n","1563/1563 [==============================] - 15s 10ms/step - loss: 0.5062 - accuracy: 0.8370 - val_loss: 1.5158 - val_accuracy: 0.6384\n","\n","Epoch 00010: val_loss did not improve from 1.05421\n","Epoch 11/50\n","1563/1563 [==============================] - 15s 10ms/step - loss: 0.4837 - accuracy: 0.8469 - val_loss: 1.7397 - val_accuracy: 0.6442\n","\n","Epoch 00011: val_loss did not improve from 1.05421\n","Epoch 12/50\n","1563/1563 [==============================] - 15s 10ms/step - loss: 0.4437 - accuracy: 0.8611 - val_loss: 1.6680 - val_accuracy: 0.6475\n","\n","Epoch 00012: val_loss did not improve from 1.05421\n","Epoch 13/50\n","1563/1563 [==============================] - 15s 10ms/step - loss: 0.4378 - accuracy: 0.8673 - val_loss: 1.6590 - val_accuracy: 0.6370\n","\n","Epoch 00013: val_loss did not improve from 1.05421\n","Epoch 14/50\n","1563/1563 [==============================] - 15s 10ms/step - loss: 0.4205 - accuracy: 0.8759 - val_loss: 2.1366 - val_accuracy: 0.6530\n","\n","Epoch 00014: val_loss did not improve from 1.05421\n","Epoch 15/50\n","1563/1563 [==============================] - 15s 10ms/step - loss: 0.4062 - accuracy: 0.8822 - val_loss: 2.2701 - val_accuracy: 0.6494\n","\n","Epoch 00015: val_loss did not improve from 1.05421\n","Epoch 16/50\n","1563/1563 [==============================] - 15s 10ms/step - loss: 0.3998 - accuracy: 0.8848 - val_loss: 2.2029 - val_accuracy: 0.6349\n","\n","Epoch 00016: val_loss did not improve from 1.05421\n","Epoch 17/50\n","1563/1563 [==============================] - 15s 10ms/step - loss: 0.3870 - accuracy: 0.8908 - val_loss: 1.8716 - val_accuracy: 0.6180\n","\n","Epoch 00017: val_loss did not improve from 1.05421\n","Epoch 18/50\n","1563/1563 [==============================] - 15s 10ms/step - loss: 0.3902 - accuracy: 0.8929 - val_loss: 2.2894 - val_accuracy: 0.6608\n","\n","Epoch 00018: val_loss did not improve from 1.05421\n","Epoch 19/50\n","1563/1563 [==============================] - 15s 10ms/step - loss: 0.3828 - accuracy: 0.8978 - val_loss: 2.4905 - val_accuracy: 0.6615\n","\n","Epoch 00019: val_loss did not improve from 1.05421\n","Epoch 20/50\n","1563/1563 [==============================] - 15s 10ms/step - loss: 0.4211 - accuracy: 0.8970 - val_loss: 2.4968 - val_accuracy: 0.6614\n","\n","Epoch 00020: val_loss did not improve from 1.05421\n","Epoch 21/50\n","1563/1563 [==============================] - 15s 10ms/step - loss: 0.3806 - accuracy: 0.9014 - val_loss: 2.6870 - val_accuracy: 0.6693\n","\n","Epoch 00021: val_loss did not improve from 1.05421\n","Epoch 22/50\n","1563/1563 [==============================] - 15s 10ms/step - loss: 0.3760 - accuracy: 0.9055 - val_loss: 2.6221 - val_accuracy: 0.6534\n","\n","Epoch 00022: val_loss did not improve from 1.05421\n","Epoch 23/50\n","1563/1563 [==============================] - 15s 10ms/step - loss: 0.4552 - accuracy: 0.9058 - val_loss: 3.1732 - val_accuracy: 0.6633\n","\n","Epoch 00023: val_loss did not improve from 1.05421\n","Epoch 24/50\n","1563/1563 [==============================] - 16s 10ms/step - loss: 0.3870 - accuracy: 0.9048 - val_loss: 3.6850 - val_accuracy: 0.6582\n","\n","Epoch 00024: val_loss did not improve from 1.05421\n","Epoch 25/50\n","1563/1563 [==============================] - 15s 10ms/step - loss: 0.3784 - accuracy: 0.9088 - val_loss: 3.1095 - val_accuracy: 0.6506\n","\n","Epoch 00025: val_loss did not improve from 1.05421\n","Epoch 26/50\n","1563/1563 [==============================] - 15s 10ms/step - loss: 0.3951 - accuracy: 0.9074 - val_loss: 3.6310 - val_accuracy: 0.6434\n","\n","Epoch 00026: val_loss did not improve from 1.05421\n","Epoch 27/50\n","1563/1563 [==============================] - 15s 10ms/step - loss: 0.3778 - accuracy: 0.9118 - val_loss: 3.0024 - val_accuracy: 0.6388\n","\n","Epoch 00027: val_loss did not improve from 1.05421\n","Epoch 28/50\n","1563/1563 [==============================] - 16s 10ms/step - loss: 0.3900 - accuracy: 0.9134 - val_loss: 2.7358 - val_accuracy: 0.6479\n","\n","Epoch 00028: val_loss did not improve from 1.05421\n","Epoch 29/50\n","1563/1563 [==============================] - 15s 10ms/step - loss: 0.3889 - accuracy: 0.9140 - val_loss: 3.8691 - val_accuracy: 0.6617\n","\n","Epoch 00029: val_loss did not improve from 1.05421\n","Epoch 30/50\n","1563/1563 [==============================] - 16s 10ms/step - loss: 0.3936 - accuracy: 0.9136 - val_loss: 3.7189 - val_accuracy: 0.6557\n","\n","Epoch 00030: val_loss did not improve from 1.05421\n","Epoch 31/50\n","1563/1563 [==============================] - 15s 10ms/step - loss: 0.3890 - accuracy: 0.9155 - val_loss: 3.8694 - val_accuracy: 0.6709\n","\n","Epoch 00031: val_loss did not improve from 1.05421\n","Epoch 32/50\n","1563/1563 [==============================] - 15s 10ms/step - loss: 0.7065 - accuracy: 0.9178 - val_loss: 4.3935 - val_accuracy: 0.6347\n","\n","Epoch 00032: val_loss did not improve from 1.05421\n","Epoch 33/50\n","1563/1563 [==============================] - 15s 10ms/step - loss: 0.3885 - accuracy: 0.9184 - val_loss: 4.2202 - val_accuracy: 0.6398\n","\n","Epoch 00033: val_loss did not improve from 1.05421\n","Epoch 34/50\n","1563/1563 [==============================] - 15s 10ms/step - loss: 0.4016 - accuracy: 0.9176 - val_loss: 3.3418 - val_accuracy: 0.6304\n","\n","Epoch 00034: val_loss did not improve from 1.05421\n","Epoch 35/50\n","1563/1563 [==============================] - 15s 10ms/step - loss: 2.3743 - accuracy: 0.9167 - val_loss: 2.6848 - val_accuracy: 0.5770\n","\n","Epoch 00035: val_loss did not improve from 1.05421\n","Epoch 36/50\n","1563/1563 [==============================] - 15s 10ms/step - loss: 0.4148 - accuracy: 0.9188 - val_loss: 4.1296 - val_accuracy: 0.6543\n","\n","Epoch 00036: val_loss did not improve from 1.05421\n","Epoch 37/50\n","1563/1563 [==============================] - 15s 10ms/step - loss: 0.7416 - accuracy: 0.9226 - val_loss: 4.0310 - val_accuracy: 0.6614\n","\n","Epoch 00037: val_loss did not improve from 1.05421\n","Epoch 38/50\n","1563/1563 [==============================] - 16s 10ms/step - loss: 0.4033 - accuracy: 0.9216 - val_loss: 4.1231 - val_accuracy: 0.6386\n","\n","Epoch 00038: val_loss did not improve from 1.05421\n","Epoch 39/50\n","1563/1563 [==============================] - 15s 10ms/step - loss: 0.4418 - accuracy: 0.9182 - val_loss: 4.1361 - val_accuracy: 0.6458\n","\n","Epoch 00039: val_loss did not improve from 1.05421\n","Epoch 40/50\n","1563/1563 [==============================] - 15s 10ms/step - loss: 0.4261 - accuracy: 0.9213 - val_loss: 6.2295 - val_accuracy: 0.6479\n","\n","Epoch 00040: val_loss did not improve from 1.05421\n","Epoch 41/50\n","1563/1563 [==============================] - 15s 10ms/step - loss: 0.4438 - accuracy: 0.9203 - val_loss: 4.3829 - val_accuracy: 0.6446\n","\n","Epoch 00041: val_loss did not improve from 1.05421\n","Epoch 42/50\n","1563/1563 [==============================] - 15s 10ms/step - loss: 0.4346 - accuracy: 0.9189 - val_loss: 4.7748 - val_accuracy: 0.6596\n","\n","Epoch 00042: val_loss did not improve from 1.05421\n","Epoch 43/50\n","1563/1563 [==============================] - 16s 10ms/step - loss: 0.4636 - accuracy: 0.9215 - val_loss: 3.6765 - val_accuracy: 0.6049\n","\n","Epoch 00043: val_loss did not improve from 1.05421\n","Epoch 44/50\n","1563/1563 [==============================] - 15s 10ms/step - loss: 0.4346 - accuracy: 0.9240 - val_loss: 5.0693 - val_accuracy: 0.6480\n","\n","Epoch 00044: val_loss did not improve from 1.05421\n","Epoch 45/50\n","1563/1563 [==============================] - 15s 10ms/step - loss: 0.4549 - accuracy: 0.9240 - val_loss: 6.3709 - val_accuracy: 0.6699\n","\n","Epoch 00045: val_loss did not improve from 1.05421\n","Epoch 46/50\n","1563/1563 [==============================] - 15s 10ms/step - loss: 0.4683 - accuracy: 0.9230 - val_loss: 6.2613 - val_accuracy: 0.6686\n","\n","Epoch 00046: val_loss did not improve from 1.05421\n","Epoch 47/50\n","1563/1563 [==============================] - 15s 10ms/step - loss: 0.4735 - accuracy: 0.9230 - val_loss: 5.3870 - val_accuracy: 0.6667\n","\n","Epoch 00047: val_loss did not improve from 1.05421\n","Epoch 48/50\n","1563/1563 [==============================] - 15s 10ms/step - loss: 0.4718 - accuracy: 0.9245 - val_loss: 6.0083 - val_accuracy: 0.6588\n","\n","Epoch 00048: val_loss did not improve from 1.05421\n","Epoch 49/50\n","1563/1563 [==============================] - 16s 10ms/step - loss: 0.4859 - accuracy: 0.9264 - val_loss: 5.6500 - val_accuracy: 0.6470\n","\n","Epoch 00049: val_loss did not improve from 1.05421\n","Epoch 50/50\n","1563/1563 [==============================] - 15s 10ms/step - loss: 0.4651 - accuracy: 0.9263 - val_loss: 4.8775 - val_accuracy: 0.6237\n","\n","Epoch 00050: val_loss did not improve from 1.05421\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fXuvKUV23DIO","executionInfo":{"status":"ok","timestamp":1626367562698,"user_tz":-330,"elapsed":8,"user":{"displayName":"ROHIT KUMAR","photoUrl":"","userId":"05114210246644333889"}},"outputId":"743d7d95-adf9-47b6-8f95-0d9e4068c016"},"source":["## Model 5\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, GlobalAveragePooling2D\n","\n","# build the model object\n","model_5 = Sequential()\n","\n","# CONV_1: add CONV layer with RELU activation and depth = 32 kernels\n","model_5.add(Conv2D(32, kernel_size=(5, 5), padding='same',activation='relu',input_shape=(32,32,3)))\n","model_5.add(Conv2D(64, kernel_size=(3, 3), padding='same',activation='relu',input_shape=(32,32,3)))\n","model_5.add(Conv2D(128, kernel_size=(3, 3), padding='same',activation='relu',input_shape=(32,32,3)))\n","# POOL_1: downsample the image to choose the best features \n","model_5.add(MaxPooling2D(pool_size=(2, 2)))\n","\n","# CONV_2: here we increase the depth to 64\n","model_5.add(Conv2D(64, (3, 3),padding='same', activation='relu'))\n","model_5.add(Conv2D(128, (3, 3), activation='relu'))\n","# POOL_2: more downsampling\n","model_5.add(MaxPooling2D(pool_size=(2, 2)))\n","\n","# flatten since too many dimensions, we only want a classification output\n","model_5.add(Flatten())\n","\n","# FC_1: fully connected to get all relevant data\n","model_5.add(Dense(64, activation='relu'))\n","\n","# FC_2: output a softmax to squash the matrix into output probabilities for the 10 classes\n","model_5.add(Dense(10, activation='softmax'))\n","\n","model_5.summary()"],"id":"fXuvKUV23DIO","execution_count":20,"outputs":[{"output_type":"stream","text":["Model: \"sequential_4\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","conv2d_20 (Conv2D)           (None, 32, 32, 32)        2432      \n","_________________________________________________________________\n","conv2d_21 (Conv2D)           (None, 32, 32, 64)        18496     \n","_________________________________________________________________\n","conv2d_22 (Conv2D)           (None, 32, 32, 128)       73856     \n","_________________________________________________________________\n","max_pooling2d_8 (MaxPooling2 (None, 16, 16, 128)       0         \n","_________________________________________________________________\n","conv2d_23 (Conv2D)           (None, 16, 16, 64)        73792     \n","_________________________________________________________________\n","conv2d_24 (Conv2D)           (None, 14, 14, 128)       73856     \n","_________________________________________________________________\n","max_pooling2d_9 (MaxPooling2 (None, 7, 7, 128)         0         \n","_________________________________________________________________\n","flatten_4 (Flatten)          (None, 6272)              0         \n","_________________________________________________________________\n","dense_8 (Dense)              (None, 64)                401472    \n","_________________________________________________________________\n","dense_9 (Dense)              (None, 10)                650       \n","=================================================================\n","Total params: 644,554\n","Trainable params: 644,554\n","Non-trainable params: 0\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3fq_F-lU3SSm","executionInfo":{"status":"ok","timestamp":1626368305933,"user_tz":-330,"elapsed":743238,"user":{"displayName":"ROHIT KUMAR","photoUrl":"","userId":"05114210246644333889"}},"outputId":"e75bd820-0208-4e15-f2b7-ae988857d9b7"},"source":["# compile the model\n","model_5.compile(loss='categorical_crossentropy', optimizer='rmsprop', \n","              metrics=['accuracy'])\n","from tensorflow.keras.callbacks import ModelCheckpoint   \n","\n","# train the model\n","checkpointer = ModelCheckpoint(filepath='model_5.weights.best.hdf5', verbose=1, \n","                               save_best_only=True)\n","hist = model_5.fit(X_train, y_train, batch_size=32, epochs=50,\n","          validation_data=(X_test, y_test), callbacks=[checkpointer], \n","          verbose=1, shuffle=True)"],"id":"3fq_F-lU3SSm","execution_count":21,"outputs":[{"output_type":"stream","text":["Epoch 1/50\n","1563/1563 [==============================] - 15s 9ms/step - loss: 1.5688 - accuracy: 0.4344 - val_loss: 1.2023 - val_accuracy: 0.5822\n","\n","Epoch 00001: val_loss improved from inf to 1.20233, saving model to model_5.weights.best.hdf5\n","Epoch 2/50\n","1563/1563 [==============================] - 14s 9ms/step - loss: 1.0300 - accuracy: 0.6388 - val_loss: 0.9799 - val_accuracy: 0.6591\n","\n","Epoch 00002: val_loss improved from 1.20233 to 0.97990, saving model to model_5.weights.best.hdf5\n","Epoch 3/50\n","1563/1563 [==============================] - 14s 9ms/step - loss: 0.8099 - accuracy: 0.7207 - val_loss: 1.0511 - val_accuracy: 0.6632\n","\n","Epoch 00003: val_loss did not improve from 0.97990\n","Epoch 4/50\n","1563/1563 [==============================] - 14s 9ms/step - loss: 0.6917 - accuracy: 0.7653 - val_loss: 0.8242 - val_accuracy: 0.7206\n","\n","Epoch 00004: val_loss improved from 0.97990 to 0.82424, saving model to model_5.weights.best.hdf5\n","Epoch 5/50\n","1563/1563 [==============================] - 14s 9ms/step - loss: 0.6128 - accuracy: 0.7945 - val_loss: 0.8351 - val_accuracy: 0.7307\n","\n","Epoch 00005: val_loss did not improve from 0.82424\n","Epoch 6/50\n","1563/1563 [==============================] - 14s 9ms/step - loss: 0.5696 - accuracy: 0.8098 - val_loss: 0.9732 - val_accuracy: 0.7282\n","\n","Epoch 00006: val_loss did not improve from 0.82424\n","Epoch 7/50\n","1563/1563 [==============================] - 14s 9ms/step - loss: 0.5213 - accuracy: 0.8271 - val_loss: 0.9166 - val_accuracy: 0.7396\n","\n","Epoch 00007: val_loss did not improve from 0.82424\n","Epoch 8/50\n","1563/1563 [==============================] - 14s 9ms/step - loss: 0.5016 - accuracy: 0.8362 - val_loss: 1.2881 - val_accuracy: 0.7186\n","\n","Epoch 00008: val_loss did not improve from 0.82424\n","Epoch 9/50\n","1563/1563 [==============================] - 14s 9ms/step - loss: 0.4817 - accuracy: 0.8421 - val_loss: 1.0447 - val_accuracy: 0.6715\n","\n","Epoch 00009: val_loss did not improve from 0.82424\n","Epoch 10/50\n","1563/1563 [==============================] - 14s 9ms/step - loss: 0.4732 - accuracy: 0.8468 - val_loss: 0.9141 - val_accuracy: 0.7305\n","\n","Epoch 00010: val_loss did not improve from 0.82424\n","Epoch 11/50\n","1563/1563 [==============================] - 14s 9ms/step - loss: 0.4587 - accuracy: 0.8515 - val_loss: 1.0152 - val_accuracy: 0.7382\n","\n","Epoch 00011: val_loss did not improve from 0.82424\n","Epoch 12/50\n","1563/1563 [==============================] - 14s 9ms/step - loss: 0.4512 - accuracy: 0.8544 - val_loss: 0.9804 - val_accuracy: 0.7485\n","\n","Epoch 00012: val_loss did not improve from 0.82424\n","Epoch 13/50\n","1563/1563 [==============================] - 14s 9ms/step - loss: 0.4380 - accuracy: 0.8588 - val_loss: 1.0632 - val_accuracy: 0.6470\n","\n","Epoch 00013: val_loss did not improve from 0.82424\n","Epoch 14/50\n","1563/1563 [==============================] - 14s 9ms/step - loss: 0.4328 - accuracy: 0.8637 - val_loss: 1.2512 - val_accuracy: 0.7237\n","\n","Epoch 00014: val_loss did not improve from 0.82424\n","Epoch 15/50\n","1563/1563 [==============================] - 14s 9ms/step - loss: 0.4412 - accuracy: 0.8628 - val_loss: 1.4918 - val_accuracy: 0.7380\n","\n","Epoch 00015: val_loss did not improve from 0.82424\n","Epoch 16/50\n","1563/1563 [==============================] - 14s 9ms/step - loss: 0.4315 - accuracy: 0.8650 - val_loss: 1.1838 - val_accuracy: 0.7466\n","\n","Epoch 00016: val_loss did not improve from 0.82424\n","Epoch 17/50\n","1563/1563 [==============================] - 14s 9ms/step - loss: 0.4272 - accuracy: 0.8666 - val_loss: 1.0100 - val_accuracy: 0.7188\n","\n","Epoch 00017: val_loss did not improve from 0.82424\n","Epoch 18/50\n","1563/1563 [==============================] - 14s 9ms/step - loss: 0.4261 - accuracy: 0.8696 - val_loss: 1.0303 - val_accuracy: 0.7549\n","\n","Epoch 00018: val_loss did not improve from 0.82424\n","Epoch 19/50\n","1563/1563 [==============================] - 14s 9ms/step - loss: 0.4243 - accuracy: 0.8723 - val_loss: 1.0254 - val_accuracy: 0.7560\n","\n","Epoch 00019: val_loss did not improve from 0.82424\n","Epoch 20/50\n","1563/1563 [==============================] - 14s 9ms/step - loss: 0.4150 - accuracy: 0.8723 - val_loss: 1.2735 - val_accuracy: 0.7310\n","\n","Epoch 00020: val_loss did not improve from 0.82424\n","Epoch 21/50\n","1563/1563 [==============================] - 14s 9ms/step - loss: 0.4172 - accuracy: 0.8736 - val_loss: 1.1291 - val_accuracy: 0.7301\n","\n","Epoch 00021: val_loss did not improve from 0.82424\n","Epoch 22/50\n","1563/1563 [==============================] - 14s 9ms/step - loss: 0.4265 - accuracy: 0.8711 - val_loss: 1.4122 - val_accuracy: 0.7203\n","\n","Epoch 00022: val_loss did not improve from 0.82424\n","Epoch 23/50\n","1563/1563 [==============================] - 14s 9ms/step - loss: 0.4246 - accuracy: 0.8725 - val_loss: 1.2214 - val_accuracy: 0.7380\n","\n","Epoch 00023: val_loss did not improve from 0.82424\n","Epoch 24/50\n","1563/1563 [==============================] - 14s 9ms/step - loss: 0.4245 - accuracy: 0.8737 - val_loss: 1.1221 - val_accuracy: 0.7369\n","\n","Epoch 00024: val_loss did not improve from 0.82424\n","Epoch 25/50\n","1563/1563 [==============================] - 14s 9ms/step - loss: 0.4167 - accuracy: 0.8768 - val_loss: 1.2444 - val_accuracy: 0.7252\n","\n","Epoch 00025: val_loss did not improve from 0.82424\n","Epoch 26/50\n","1563/1563 [==============================] - 14s 9ms/step - loss: 0.4053 - accuracy: 0.8802 - val_loss: 1.2874 - val_accuracy: 0.7238\n","\n","Epoch 00026: val_loss did not improve from 0.82424\n","Epoch 27/50\n","1563/1563 [==============================] - 14s 9ms/step - loss: 0.4369 - accuracy: 0.8766 - val_loss: 1.3756 - val_accuracy: 0.7117\n","\n","Epoch 00027: val_loss did not improve from 0.82424\n","Epoch 28/50\n","1563/1563 [==============================] - 14s 9ms/step - loss: 0.4852 - accuracy: 0.8767 - val_loss: 1.7914 - val_accuracy: 0.6383\n","\n","Epoch 00028: val_loss did not improve from 0.82424\n","Epoch 29/50\n","1563/1563 [==============================] - 14s 9ms/step - loss: 0.4247 - accuracy: 0.8793 - val_loss: 2.3712 - val_accuracy: 0.7262\n","\n","Epoch 00029: val_loss did not improve from 0.82424\n","Epoch 30/50\n","1563/1563 [==============================] - 14s 9ms/step - loss: 0.5039 - accuracy: 0.8798 - val_loss: 1.3707 - val_accuracy: 0.6667\n","\n","Epoch 00030: val_loss did not improve from 0.82424\n","Epoch 31/50\n","1563/1563 [==============================] - 14s 9ms/step - loss: 0.4172 - accuracy: 0.8777 - val_loss: 1.5955 - val_accuracy: 0.7310\n","\n","Epoch 00031: val_loss did not improve from 0.82424\n","Epoch 32/50\n","1563/1563 [==============================] - 14s 9ms/step - loss: 0.4422 - accuracy: 0.8771 - val_loss: 1.9222 - val_accuracy: 0.7095\n","\n","Epoch 00032: val_loss did not improve from 0.82424\n","Epoch 33/50\n","1563/1563 [==============================] - 15s 9ms/step - loss: 0.4256 - accuracy: 0.8755 - val_loss: 1.2732 - val_accuracy: 0.7043\n","\n","Epoch 00033: val_loss did not improve from 0.82424\n","Epoch 34/50\n","1563/1563 [==============================] - 15s 9ms/step - loss: 0.4227 - accuracy: 0.8778 - val_loss: 1.1301 - val_accuracy: 0.7102\n","\n","Epoch 00034: val_loss did not improve from 0.82424\n","Epoch 35/50\n","1563/1563 [==============================] - 14s 9ms/step - loss: 0.4446 - accuracy: 0.8748 - val_loss: 1.8589 - val_accuracy: 0.7434\n","\n","Epoch 00035: val_loss did not improve from 0.82424\n","Epoch 36/50\n","1563/1563 [==============================] - 14s 9ms/step - loss: 0.4374 - accuracy: 0.8720 - val_loss: 1.5549 - val_accuracy: 0.7306\n","\n","Epoch 00036: val_loss did not improve from 0.82424\n","Epoch 37/50\n","1563/1563 [==============================] - 15s 9ms/step - loss: 0.4440 - accuracy: 0.8710 - val_loss: 1.5442 - val_accuracy: 0.6963\n","\n","Epoch 00037: val_loss did not improve from 0.82424\n","Epoch 38/50\n","1563/1563 [==============================] - 15s 9ms/step - loss: 0.9621 - accuracy: 0.8701 - val_loss: 1.4417 - val_accuracy: 0.7043\n","\n","Epoch 00038: val_loss did not improve from 0.82424\n","Epoch 39/50\n","1563/1563 [==============================] - 14s 9ms/step - loss: 0.4412 - accuracy: 0.8734 - val_loss: 1.2162 - val_accuracy: 0.7281\n","\n","Epoch 00039: val_loss did not improve from 0.82424\n","Epoch 40/50\n","1563/1563 [==============================] - 14s 9ms/step - loss: 0.5734 - accuracy: 0.8668 - val_loss: 2.8979 - val_accuracy: 0.6562\n","\n","Epoch 00040: val_loss did not improve from 0.82424\n","Epoch 41/50\n","1563/1563 [==============================] - 14s 9ms/step - loss: 0.4498 - accuracy: 0.8688 - val_loss: 1.9099 - val_accuracy: 0.7210\n","\n","Epoch 00041: val_loss did not improve from 0.82424\n","Epoch 42/50\n","1563/1563 [==============================] - 14s 9ms/step - loss: 0.4648 - accuracy: 0.8663 - val_loss: 1.6033 - val_accuracy: 0.7189\n","\n","Epoch 00042: val_loss did not improve from 0.82424\n","Epoch 43/50\n","1563/1563 [==============================] - 14s 9ms/step - loss: 0.4693 - accuracy: 0.8650 - val_loss: 1.1560 - val_accuracy: 0.7178\n","\n","Epoch 00043: val_loss did not improve from 0.82424\n","Epoch 44/50\n","1563/1563 [==============================] - 14s 9ms/step - loss: 0.4733 - accuracy: 0.8632 - val_loss: 1.9446 - val_accuracy: 0.4693\n","\n","Epoch 00044: val_loss did not improve from 0.82424\n","Epoch 45/50\n","1563/1563 [==============================] - 14s 9ms/step - loss: 0.4979 - accuracy: 0.8621 - val_loss: 1.2713 - val_accuracy: 0.6913\n","\n","Epoch 00045: val_loss did not improve from 0.82424\n","Epoch 46/50\n","1563/1563 [==============================] - 14s 9ms/step - loss: 0.5121 - accuracy: 0.8545 - val_loss: 1.1066 - val_accuracy: 0.7052\n","\n","Epoch 00046: val_loss did not improve from 0.82424\n","Epoch 47/50\n","1563/1563 [==============================] - 14s 9ms/step - loss: 0.5057 - accuracy: 0.8575 - val_loss: 1.4820 - val_accuracy: 0.6761\n","\n","Epoch 00047: val_loss did not improve from 0.82424\n","Epoch 48/50\n","1563/1563 [==============================] - 14s 9ms/step - loss: 0.4960 - accuracy: 0.8582 - val_loss: 1.1123 - val_accuracy: 0.6940\n","\n","Epoch 00048: val_loss did not improve from 0.82424\n","Epoch 49/50\n","1563/1563 [==============================] - 14s 9ms/step - loss: 0.5128 - accuracy: 0.8608 - val_loss: 1.3444 - val_accuracy: 0.7339\n","\n","Epoch 00049: val_loss did not improve from 0.82424\n","Epoch 50/50\n","1563/1563 [==============================] - 14s 9ms/step - loss: 0.5800 - accuracy: 0.8563 - val_loss: 1.1637 - val_accuracy: 0.7318\n","\n","Epoch 00050: val_loss did not improve from 0.82424\n"],"name":"stdout"}]}]}